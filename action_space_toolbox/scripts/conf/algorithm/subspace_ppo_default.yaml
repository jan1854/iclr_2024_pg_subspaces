# TODO: Most parameters should be in a default PPO config
name: "subspace_ppo"

algorithm:
  _target_: rl_subspace_optimization.subspace_ppo.SubspacePPO
  hessian_max_iter: 100
  hessian_tolerance: 1e-3
  num_hessian_eigenvectors: 10
  warmup_steps_orig_space: 10000
  policy: "MlpPolicy"
  device: "auto"
  tensorboard_log: tensorboard

training:
  steps: 1000000
  n_envs: 1