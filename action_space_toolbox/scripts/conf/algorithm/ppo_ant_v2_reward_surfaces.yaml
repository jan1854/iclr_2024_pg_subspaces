name: "ppo"

defaults:
  - optimizer@algorithm.policy_kwargs.optimizer: adam

algorithm:
  _target_: stable_baselines3.PPO
  policy: "MlpPolicy"
  policy_kwargs:
    optimizer: ???
  device: "auto"
  tensorboard_log: tensorboard
  batch_size: 32
  n_steps: 512
  gamma: 0.98
  learning_rate: 1.90609e-05
  ent_coef: 4.9646e-07
  clip_range: 0.1
  n_epochs: 10
  gae_lambda: 0.8
  max_grad_norm: 0.6
  vf_coef: 0.677239

training:
  steps: 10_000_000
  n_envs: 1